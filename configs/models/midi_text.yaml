model_config: 
  model_name: midi_text
  projection_dim: 512             # dimensionality of the multimodal projection layer
  temperature: null
  midi:
    dict_file: './pianobind/preprocess/midi/dict/CP.pkl'
    name: 'MidiBert'
    debug: false
    ckpt: null
    # ckpt: './MidiBERT_utils/checkpoints/pretrain_model.ckpt'
    root: './Data/Annotation/Token_CP/'
    datasets:
      - 'custom'
    num_workers: 5
    batch_size: 1
    mask_percent: 0.15
    max_seq_len: 512
    hs: 768
    lr: 0.00002
    cpu: false
    cuda_devices:
      - 1
    segment_mode: 'token'
    save_avg_emb: false
    use_finetune_checkpoint: false
    use_checkpoint: false
    task: 'emotion'
    class_num: null
    index_layer: 12
    hidden_size: 768
    num_hidden_layers: 6 
  audio: 
    model: ModifiedResNet         # name of the audio backbone model (ModifiedResNet supported)
    pooling: attention            # pooling mechanism to obtain fixed-size audio features. One of [average, attention]
    audio_len_seconds: 20         # max length in seconds
    hidden_size: 256              # dimensionality of the hidden layers in the resnet conv layers
    conv_out_channels: 16         # number of output channels in the resnet conv layers
    n_mels: 128                   # number of mel filterbanks to use in melspectrogram
    sample_rate: 16000            # sample rate of the input audio
    n_fft: 1024                   # size of the FFT
    f_min: 0                      # min frequency in the spectrogram
    f_max: 11025                  # max frequency in the spectrogram

  text: 
    model: RobertaMIDI    
    pretrained: roberta-base      
    frozen_layers:               
    num_hidden_layers: 12         
    hidden_size: 768              
    num_attention_heads: 12       
    vocab_size: 50265             
    max_position_embeddings: 512  
    attention_dropout: 0.2        
    dropout: 0.2                  
  loss: clip                     